{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Garbage Classification using keras and transfer learning","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true}},{"cell_type":"markdown","source":"# Import Required Libraries","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd \nimport random\nimport os\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport keras.applications.xception as xception\nimport zipfile\nimport sys\nimport time\nimport tensorflow.keras as keras\nimport tensorflow as tf\nimport re\n\nfrom PIL import Image\nfrom keras.layers import Input, Conv2D, Dense, Flatten, MaxPooling2D, Input, GlobalAveragePooling2D\nfrom keras.layers.experimental.preprocessing import Normalization\nfrom keras.models import Model, Sequential\nfrom keras.preprocessing import image\nfrom keras.utils import to_categorical\nfrom keras.layers import Lambda\nfrom keras.callbacks import EarlyStopping\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report\n\nprint('setup successful!')","metadata":{"execution":{"iopub.status.busy":"2022-06-01T07:57:07.720768Z","iopub.execute_input":"2022-06-01T07:57:07.721111Z","iopub.status.idle":"2022-06-01T07:57:13.325252Z","shell.execute_reply.started":"2022-06-01T07:57:07.721076Z","shell.execute_reply":"2022-06-01T07:57:13.324467Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Define Constants","metadata":{}},{"cell_type":"code","source":"# Increasing the image size didn't result in increasing the training accuracy\nIMAGE_WIDTH = 320    \nIMAGE_HEIGHT = 320\nIMAGE_SIZE=(IMAGE_WIDTH, IMAGE_HEIGHT)\nIMAGE_CHANNELS = 3\n\n\n# Path where our data is located\nbase_path = \"../input/garbage-classification/garbage_classification/\"\n\n# Dictionary to save our 12 classes\ncategories = {0: 'paper', 1: 'cardboard', 2: 'plastic', 3: 'metal', 4: 'trash', 5: 'battery',\n              6: 'shoes', 7: 'clothes', 8: 'green-glass', 9: 'brown-glass', 10: 'white-glass',\n              11: 'biological'}\n\nprint('defining constants successful!')","metadata":{"execution":{"iopub.status.busy":"2022-06-01T07:57:13.329073Z","iopub.execute_input":"2022-06-01T07:57:13.329335Z","iopub.status.idle":"2022-06-01T07:57:13.336361Z","shell.execute_reply.started":"2022-06-01T07:57:13.329308Z","shell.execute_reply":"2022-06-01T07:57:13.335453Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Create DataFrame","metadata":{"trusted":true}},{"cell_type":"code","source":"# Add class name prefix to filename. So for example \"/paper104.jpg\" become \"paper/paper104.jpg\"\ndef add_class_name_prefix(df, col_name):\n    df[col_name] = df[col_name].apply(lambda x: x[:re.search(\"\\d\",x).start()] + '/' + x)\n    return df\n\n# list conatining all the filenames in the dataset\nfilenames_list = []\n# list to store the corresponding category, note that each folder of the dataset has one class of data\ncategories_list = []\n\nfor category in categories:\n    filenames = os.listdir(base_path + categories[category])\n    \n    filenames_list = filenames_list  +filenames\n    categories_list = categories_list + [category] * len(filenames)\n    \ndf = pd.DataFrame({\n    'filename': filenames_list,\n    'category': categories_list\n})\n\ndf = add_class_name_prefix(df, 'filename')\n\n# Shuffle the dataframe\ndf = df.sample(frac=1).reset_index(drop=True)\n\nprint('number of elements = ' , len(df))","metadata":{"execution":{"iopub.status.busy":"2022-06-01T07:57:13.337961Z","iopub.execute_input":"2022-06-01T07:57:13.338726Z","iopub.status.idle":"2022-06-01T07:57:14.411393Z","shell.execute_reply.started":"2022-06-01T07:57:13.338682Z","shell.execute_reply":"2022-06-01T07:57:14.410465Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"execution":{"iopub.status.busy":"2022-06-01T07:57:14.412638Z","iopub.execute_input":"2022-06-01T07:57:14.413147Z","iopub.status.idle":"2022-06-01T07:57:14.429768Z","shell.execute_reply.started":"2022-06-01T07:57:14.413106Z","shell.execute_reply":"2022-06-01T07:57:14.429075Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# see sample image, you can run the same cell again to get a different image\nrandom_row = random.randint(0, len(df)-1)\nsample = df.iloc[random_row]\nrandomimage = image.load_img(base_path +sample['filename'])\nprint(sample['filename'])\nplt.imshow(randomimage)","metadata":{"execution":{"iopub.status.busy":"2022-06-01T07:57:14.433372Z","iopub.execute_input":"2022-06-01T07:57:14.433628Z","iopub.status.idle":"2022-06-01T07:57:14.668657Z","shell.execute_reply.started":"2022-06-01T07:57:14.433603Z","shell.execute_reply":"2022-06-01T07:57:14.667786Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Viusalize the Categories Distribution","metadata":{}},{"cell_type":"code","source":"df_visualization = df.copy()\n# Change the catgegories from numbers to names\ndf_visualization['category'] = df_visualization['category'].apply(lambda x:categories[x] )\n\ndf_visualization['category'].value_counts().plot.bar(x = 'count', y = 'category' )\n\nplt.xlabel(\"Garbage Classes\", labelpad=14)\nplt.ylabel(\"Images Count\", labelpad=14)\nplt.title(\"Count of images per class\", y=1.02);","metadata":{"execution":{"iopub.status.busy":"2022-06-01T07:57:14.670271Z","iopub.execute_input":"2022-06-01T07:57:14.670504Z","iopub.status.idle":"2022-06-01T07:57:14.846716Z","shell.execute_reply.started":"2022-06-01T07:57:14.670481Z","shell.execute_reply":"2022-06-01T07:57:14.84589Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Create the model","metadata":{}},{"cell_type":"markdown","source":"The steps are:\n1. Create an xception model without the last layer and load the ImageNet pretrained weights\n2. Add a pre-processing layer\n3. Add a pooling layer followed by a softmax layer at the end","metadata":{}},{"cell_type":"code","source":"from keras.models import Sequential\nfrom keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten, Dense, Activation, BatchNormalization\nimport keras.applications.xception as xception\n\nxception_layer = xception.Xception(include_top = False, input_shape = (IMAGE_WIDTH, IMAGE_HEIGHT,IMAGE_CHANNELS),\n                       weights = '../input/xception/xception_weights_tf_dim_ordering_tf_kernels_notop.h5')\n\n# We don't want to train the imported weights\nxception_layer.trainable = False\n\n\nmodel = Sequential()\nmodel.add(keras.Input(shape=(IMAGE_WIDTH, IMAGE_HEIGHT, IMAGE_CHANNELS)))\n\n#create a custom layer to apply the preprocessing\ndef xception_preprocessing(img):\n  return xception.preprocess_input(img)\n\nmodel.add(Lambda(xception_preprocessing))\n\nmodel.add(xception_layer)\nmodel.add(tf.keras.layers.GlobalAveragePooling2D())\nmodel.add(Dense(len(categories), activation='softmax')) \n\nmodel.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['categorical_accuracy'])\n\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2022-06-01T07:57:14.848204Z","iopub.execute_input":"2022-06-01T07:57:14.848616Z","iopub.status.idle":"2022-06-01T07:57:20.32121Z","shell.execute_reply.started":"2022-06-01T07:57:14.848573Z","shell.execute_reply":"2022-06-01T07:57:20.319415Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We will use the EarlyStopping call back to stop our training if the validation_accuray is not improving for a certain number of epochs.","metadata":{}},{"cell_type":"code","source":"early_stop = EarlyStopping(patience = 2, verbose = 1, monitor='val_categorical_accuracy' , mode='max', min_delta=0.001, restore_best_weights = True)\n\ncallbacks = [early_stop]\n\nprint('call back defined!')","metadata":{"execution":{"iopub.status.busy":"2022-06-01T07:57:20.322577Z","iopub.execute_input":"2022-06-01T07:57:20.322954Z","iopub.status.idle":"2022-06-01T07:57:20.332876Z","shell.execute_reply.started":"2022-06-01T07:57:20.322923Z","shell.execute_reply":"2022-06-01T07:57:20.331735Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Split the Data Set","metadata":{}},{"cell_type":"markdown","source":"We split the training set into three separate sets:\n\n1. **The training set:** used to train our model.\n1. **The validation set**: used to double check that our model is not overfitting the training set, i.e. it can also generalise to other data other than the train data\n1. **The Test set:** Used to estimate the accuracy of the model on new data other than the ones the model used for training\nFor a competition  or for some other cases, you can split the data only to training and validation sets in order to achieve the highest  possible accuracy, without the need to properly estimate how accurate the model really is.\n\nWe split the data set as follows: 80% train set, 10% cross_validation set, and 10% test set","metadata":{}},{"cell_type":"code","source":"#Change the categories from numbers to names\ndf[\"category\"] = df[\"category\"].replace(categories) \n\n# We first split the data into two sets and then split the validate_df to two sets\ntrain_df, validate_df = train_test_split(df, test_size=0.2, random_state=42)\nvalidate_df, test_df = train_test_split(validate_df, test_size=0.5, random_state=42)\n\ntrain_df = train_df.reset_index(drop=True)\nvalidate_df = validate_df.reset_index(drop=True)\ntest_df = test_df.reset_index(drop=True)\n\ntotal_train = train_df.shape[0]\ntotal_validate = validate_df.shape[0]\n\nprint('train size = ', total_validate , 'validate size = ', total_validate, 'test size = ', test_df.shape[0])","metadata":{"execution":{"iopub.status.busy":"2022-06-01T07:57:20.334263Z","iopub.execute_input":"2022-06-01T07:57:20.334617Z","iopub.status.idle":"2022-06-01T07:57:20.357919Z","shell.execute_reply.started":"2022-06-01T07:57:20.33458Z","shell.execute_reply":"2022-06-01T07:57:20.356137Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Train the model","metadata":{}},{"cell_type":"markdown","source":"We will first create the training data generator, that will get the images from the input data directory to train on them. We will also create a generator for the validation set.\n\nApplying Data Augmentation on the training set was taking too long to be executed and the initial results didn't show much improvement than the results without augmentation, so I commented the augmentation to make the training faster. However fell free to uncomment the Data Augmentation lines in the following cell and play a bit with it.","metadata":{}},{"cell_type":"code","source":"batch_size=64\n\ntrain_datagen = image.ImageDataGenerator(\n    \n    ###  Augmentation Start  ###\n    \n    #rotation_range=30,\n    #shear_range=0.1,\n    #zoom_range=0.3,\n    #horizontal_flip=True,\n    #vertical_flip = True,\n    #width_shift_range=0.2,\n    #height_shift_range=0.2\n    \n    ##  Augmentation End  ###\n)\n\ntrain_generator = train_datagen.flow_from_dataframe(\n    train_df, \n    base_path, \n    x_col='filename',\n    y_col='category',\n    target_size=IMAGE_SIZE,\n    class_mode='categorical',\n    batch_size=batch_size\n)","metadata":{"execution":{"iopub.status.busy":"2022-06-01T07:57:20.359424Z","iopub.execute_input":"2022-06-01T07:57:20.359801Z","iopub.status.idle":"2022-06-01T07:57:28.130379Z","shell.execute_reply.started":"2022-06-01T07:57:20.359764Z","shell.execute_reply":"2022-06-01T07:57:28.12928Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"validation_datagen = image.ImageDataGenerator()\n\nvalidation_generator = validation_datagen.flow_from_dataframe(\n    validate_df, \n    base_path, \n    x_col='filename',\n    y_col='category',\n    target_size=IMAGE_SIZE,\n    class_mode='categorical',\n    batch_size=batch_size\n)","metadata":{"execution":{"iopub.status.busy":"2022-06-01T07:57:28.131719Z","iopub.execute_input":"2022-06-01T07:57:28.132256Z","iopub.status.idle":"2022-06-01T07:57:29.125347Z","shell.execute_reply.started":"2022-06-01T07:57:28.132212Z","shell.execute_reply":"2022-06-01T07:57:29.124409Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"EPOCHS = 20\nhistory = model.fit_generator(\n    train_generator, \n    epochs=EPOCHS,\n    validation_data=validation_generator,\n    validation_steps=total_validate//batch_size,\n    steps_per_epoch=total_train//batch_size,\n    callbacks=callbacks\n)","metadata":{"execution":{"iopub.status.busy":"2022-06-01T07:57:29.126605Z","iopub.execute_input":"2022-06-01T07:57:29.126957Z","iopub.status.idle":"2022-06-01T08:08:32.260625Z","shell.execute_reply.started":"2022-06-01T07:57:29.126926Z","shell.execute_reply":"2022-06-01T08:08:32.259827Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Save the Model","metadata":{}},{"cell_type":"code","source":"model.save_weights(\"model.h5\")","metadata":{"execution":{"iopub.status.busy":"2022-06-01T08:08:32.263264Z","iopub.execute_input":"2022-06-01T08:08:32.263608Z","iopub.status.idle":"2022-06-01T08:08:32.516949Z","shell.execute_reply.started":"2022-06-01T08:08:32.263577Z","shell.execute_reply":"2022-06-01T08:08:32.516069Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.save('./model.h5')","metadata":{"execution":{"iopub.status.busy":"2022-06-01T08:11:01.442874Z","iopub.execute_input":"2022-06-01T08:11:01.443281Z","iopub.status.idle":"2022-06-01T08:11:01.830017Z","shell.execute_reply.started":"2022-06-01T08:11:01.443247Z","shell.execute_reply":"2022-06-01T08:11:01.829117Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# save to .tflite format\n# Convert the model.\nconverter = tf.lite.TFLiteConverter.from_keras_model(model)\ntflite_model = converter.convert()\n\n# Save the model.\nwith open('model.tflite', 'wb') as f:\n    f.write(tflite_model)","metadata":{"execution":{"iopub.status.busy":"2022-06-01T08:11:16.980233Z","iopub.execute_input":"2022-06-01T08:11:16.980605Z","iopub.status.idle":"2022-06-01T08:11:41.47368Z","shell.execute_reply.started":"2022-06-01T08:11:16.980571Z","shell.execute_reply":"2022-06-01T08:11:41.472798Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Visualize the training process\n","metadata":{}},{"cell_type":"code","source":"fig, (ax1, ax2) = plt.subplots(2, 1)\nax1.plot(history.history['loss'], color='b', label=\"Training loss\")\nax1.plot(history.history['val_loss'], color='r', label=\"validation loss\")\nax1.set_yticks(np.arange(0, 0.7, 0.1))\nax1.legend()\n\nax2.plot(history.history['categorical_accuracy'], color='b', label=\"Training accuracy\")\nax2.plot(history.history['val_categorical_accuracy'], color='r',label=\"Validation accuracy\")\nax2.legend()\n\nlegend = plt.legend(loc='best')\nplt.tight_layout()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-06-01T08:08:32.518205Z","iopub.execute_input":"2022-06-01T08:08:32.518557Z","iopub.status.idle":"2022-06-01T08:08:32.818751Z","shell.execute_reply.started":"2022-06-01T08:08:32.518513Z","shell.execute_reply":"2022-06-01T08:08:32.817959Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Evaluate the test","metadata":{}},{"cell_type":"markdown","source":"To evaluate the performance of our model we will create a test generator to load the images from the input data directory and evaluate the results.","metadata":{}},{"cell_type":"code","source":"test_datagen = image.ImageDataGenerator()\n\ntest_generator = test_datagen.flow_from_dataframe(\n    dataframe= test_df,\n    directory=base_path,\n    x_col='filename',\n    y_col='category',\n    target_size=IMAGE_SIZE,\n    color_mode=\"rgb\",\n    class_mode=\"categorical\",\n    batch_size=1,\n    shuffle=False \n)","metadata":{"execution":{"iopub.status.busy":"2022-06-01T08:08:32.820128Z","iopub.execute_input":"2022-06-01T08:08:32.82046Z","iopub.status.idle":"2022-06-01T08:08:34.422701Z","shell.execute_reply.started":"2022-06-01T08:08:32.820422Z","shell.execute_reply":"2022-06-01T08:08:34.421117Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"filenames = test_generator.filenames\nnb_samples = len(filenames)\n\n_, accuracy = model.evaluate_generator(test_generator, nb_samples)\n\nprint('accuracy on test set = ',  round((accuracy * 100),2 ), '% ') ","metadata":{"execution":{"iopub.status.busy":"2022-06-01T08:08:34.424126Z","iopub.execute_input":"2022-06-01T08:08:34.424462Z","iopub.status.idle":"2022-06-01T08:08:52.44215Z","shell.execute_reply.started":"2022-06-01T08:08:34.424424Z","shell.execute_reply":"2022-06-01T08:08:52.441114Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Great, the accuracy is well over 90% !! (it varies from one run to another due to the random shuffling but is between 94% and 96%) \n\nBut let's have a look on the F1 score for each of the categories. For that we will be using the classification_report from the sklearn package.","metadata":{}},{"cell_type":"code","source":"# We defined at the beginning of this notebook a dictionary that maps the categories number to names, but the train generator\n# generated it's own dictionary and it has assigned different numbers to our categories and the predictions made by the model \n# will be made using the genrator's dictionary.\n\ngen_label_map = test_generator.class_indices\ngen_label_map = dict((v,k) for k,v in gen_label_map.items())\nprint(gen_label_map)","metadata":{"execution":{"iopub.status.busy":"2022-06-01T08:08:52.443693Z","iopub.execute_input":"2022-06-01T08:08:52.44434Z","iopub.status.idle":"2022-06-01T08:08:52.451387Z","shell.execute_reply.started":"2022-06-01T08:08:52.444297Z","shell.execute_reply":"2022-06-01T08:08:52.450419Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# get the model's predictions for the test set\npreds = model.predict_generator(test_generator, nb_samples)\n\n# Get the category with the highest predicted probability, the prediction is only the category's number and not name\npreds = preds.argmax(1)\n\n# Convert the predicted category's number to name \npreds = [gen_label_map[item] for item in preds]\n\n# Convert the pandas dataframe to a numpy matrix\nlabels = test_df['category'].to_numpy()\n\nprint(classification_report(labels, preds))","metadata":{"execution":{"iopub.status.busy":"2022-06-01T08:08:52.453163Z","iopub.execute_input":"2022-06-01T08:08:52.45361Z","iopub.status.idle":"2022-06-01T08:09:07.273322Z","shell.execute_reply.started":"2022-06-01T08:08:52.453573Z","shell.execute_reply":"2022-06-01T08:09:07.271862Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The table above shows among other info the F1 score of each category. In the bottom of the F1 score column notice two numbers accuracy and macro avg. Accuracy is the same accuracy that we evaluated above for the test set, it is a weighted average. \n\nHowever the macro avg (unweighted average) is a bit less than accuracy. This is because the clothes category, the category which has by far the largest number of images, has a very high F1 score, so accuracy (the weighted average) is higher than the unweighted average (macro avg).\n\nFor this problem I would consider the macro avg a better measure of accuracy as it takes an average of all the F1 scores regardless of how much data we have in the training data for each category.","metadata":{}},{"cell_type":"markdown","source":"## End Note","metadata":{}},{"cell_type":"markdown","source":"If you liked this kernel please upvote! I also created a small web app to classify the garbage images, https://mostafa-portfolio.azurewebsites.net/ feel free to play around with it!","metadata":{}}]}